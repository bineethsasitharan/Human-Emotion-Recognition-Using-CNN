# Human-Emotion-Recognition-Using-CNN
Human Emotion Recognition Using CNN

The aim of this project is to build a deep learning model using Convolutional Neural Networks (CNNs) that can accurately recognize and classify human emotions based on facial expressions captured in images. Emotion recognition has a wide range of applications, including human-computer interaction, sentiment analysis, and mental health assessment.

CNNs excel at automatically learning and extracting relevant features from images, making them particularly well-suited for tasks like facial emotion recognition. At the core of a CNN are convolutional layers that apply filters (kernels) to the input image, effectively scanning and capturing features like edges, textures, and patterns. In the context of emotion recognition, CNNs can learn to identify facial features such as eyes, eyebrows, mouth, and their spatial relationships.
